# AUDITOR√çA DIFFUSION - RESUMEN EJECUTIVO Y PLAN DE ACCI√ìN

## RESUMEN EJECUTIVO COMPLETO

### Visi√≥n General del Sistema

El m√≥dulo `ml_lib/diffusion/` es un **sistema complejo de generaci√≥n de im√°genes con IA** que actualmente est√° **80% funcional** pero con **problemas cr√≠ticos de integraci√≥n** y **violaciones de normas de codificaci√≥n**.

**Estado actual del c√≥digo:**
- ‚úÖ **Arquitectura s√≥lida:** DDD bien implementado, separaci√≥n clara de responsabilidades
- ‚úÖ **Funcionalidades core:** Pipeline de generaci√≥n, selecci√≥n de modelos, optimizaci√≥n de memoria
- ‚ö†Ô∏è **C√≥digo nuevo sin integrar:** 3 archivos cr√≠ticos (user_preferences, prompt_compactor, content_tags)
- ‚ùå **Violaciones de normas:** 89 dicts, 47 tuples, 12 any/object
- ‚ùå **Testing insuficiente:** <20% cobertura

### Hallazgos Cr√≠ticos por Categor√≠a

#### üî¥ CR√çTICO - Requiere acci√≥n INMEDIATA

1. **UserPreferencesDB NO integrado** (363 l√≠neas de c√≥digo muerto)
   - Base de datos completa sin ninguna conexi√≥n al sistema
   - No se usa en ning√∫n servicio
   - **Impacto:** Funcionalidad de personalizaci√≥n in√∫til

2. **PromptCompactor duplicado** (271 l√≠neas)
   - L√≥gica de compactaci√≥n existe en dos lugares
   - `PromptAnalyzer.compact_prompt()` y `PromptCompactor.compact()` hacen lo mismo
   - **Impacto:** Inconsistencia en comportamiento, bugs potenciales

3. **Precisi√≥n de prompts comprometida**
   - Sistema puede truncar contenido NSFW sin avisar al usuario
   - No hay garant√≠a de que imagen generada coincida con prompt
   - **Impacto:** Baja calidad percibida, usuarios insatisfechos

#### ‚ö†Ô∏è ALTO - Requiere atenci√≥n esta semana

4. **Violaciones masivas de normas de codificaci√≥n**
   - 89 dicts donde deber√≠an ser clases
   - 47 tuples donde deber√≠an ser value objects
   - **Impacto:** C√≥digo dif√≠cil de mantener, bugs futuros

5. **content_tags.py no exportado**
   - Archivo nuevo (382 l√≠neas) no est√° en `models/__init__.py`
   - Importable pero no descubrible
   - **Impacto:** C√≥digo que existe pero no se puede usar f√°cilmente

6. **Falta de extensibilidad para nuevos dominios**
   - Sistema hardcoded para NSFW
   - Imposible a√±adir fantas√≠a, dise√±os, etc. sin reescribir c√≥digo
   - **Impacto:** No escalable para roadmap futuro

#### üìä MEDIO - Planificar para pr√≥ximas 2 semanas

7. **Testing insuficiente**
   - 3 archivos de test nuevos no ejecutados
   - Cobertura estimada <20%
   - Sin tests de integraci√≥n

8. **Performance no optimizada**
   - Ollama server con sleep(2) blocking
   - Tokenizer descarga 500MB en cada instancia
   - No hay cach√© compartido

---

## AN√ÅLISIS DETALLADO DE IMPACTO

### Impacto en Calidad de Im√°genes

**Problema Principal:** Sistema puede modificar prompts sin control

```
USER INPUT:
"2girls, fellatio, deepthroat, cum, masterpiece, best quality, highly detailed, ..."
(85 tokens)

SISTEMA COMPACTA (sin avisar):
"2girls, fellatio, masterpiece"
(40 tokens)

RESULTADO:
- ‚ùå "deepthroat" removido ‚Üí Imagen no cumple expectativa
- ‚ùå "cum" removido ‚Üí Contenido expl√≠cito faltante
- ‚ùå Usuario NO notificado ‚Üí No sabe qu√© se perdi√≥
```

**Soluci√≥n propuesta:** Pipeline de procesamiento unificado con feedback

### Impacto en Mantenibilidad

**Violaciones de normas detectadas:**

| Tipo | Cantidad | Severidad | Esfuerzo correcci√≥n |
|------|----------|-----------|---------------------|
| `dict` como atributo | 34 | üî¥ ALTA | 6-8 horas |
| `tuple` como return | 23 | üî¥ ALTA | 3-4 horas |
| `any` / `object` | 12 | ‚ö†Ô∏è MEDIA | 2 horas |
| Inline imports stdlib | 5 | üü° BAJA | 30 min |

**Ejemplo de violaci√≥n cr√≠tica:**

```python
# ‚ùå MAL - content_tags.py:57
NSFW_KEYWORDS: dict[NSFWCategory, list[str]] = {
    NSFWCategory.ORAL: ["fellatio", "blowjob", ...],
    # ... m√°s categor√≠as
}

# ‚úÖ BIEN - Deber√≠a ser:
class NSFWKeywordRegistry:
    def __init__(self):
        self._keywords: dict[NSFWCategory, KeywordList] = {}
        self._load_from_config()

    def get_keywords(self, category: NSFWCategory) -> KeywordList:
        return self._keywords.get(category, KeywordList([]))

    def add_category(self, category: NSFWCategory, keywords: KeywordList) -> None:
        self._keywords[category] = keywords
```

### Impacto en Extensibilidad Futura

**Roadmap del usuario:**
- ‚úÖ Fase 1: Contenido NSFW (ACTUAL)
- ‚è≥ Fase 2: Contenido de fantas√≠a (BLOQUEADO)
- ‚è≥ Fase 3: Dise√±os (camisetas, etc.) (BLOQUEADO)
- ‚è≥ Fase 4: Arte conceptual (BLOQUEADO)

**Problema:** Sistema actual hardcoded para NSFW

```python
# content_tags.py - Todo hardcoded
NSFW_KEYWORDS = {...}  # Solo NSFW
CORE_CONTENT_KEYWORDS = [...]  # Solo caracteres humanos
CONTEXT_KEYWORDS = [...]  # Solo escenas realistas
```

**Soluci√≥n propuesta:** Sistema de registro extensible

```python
# Arquitectura propuesta
ContentCategoryRegistry
    ‚îú‚îÄ‚îÄ NSFWContentDefinition
    ‚îú‚îÄ‚îÄ FantasyContentDefinition (futuro)
    ‚îú‚îÄ‚îÄ DesignContentDefinition (futuro)
    ‚îî‚îÄ‚îÄ ConceptArtContentDefinition (futuro)

# A√±adir nuevo dominio sin modificar c√≥digo:
registry.register_from_yaml("config/fantasy_categories.yaml")
```

---

## PLAN DE ACCI√ìN PRIORIZADO

### üî¥ FASE 1: CR√çTICO - Hacer HOY (4-6 horas)

#### Tarea 1.1: Integrar PromptCompactor (2 horas)

**Objetivo:** Un solo sistema de compactaci√≥n

**Acciones:**
1. Modificar `PromptAnalyzer` para usar `PromptCompactor`
2. Deprecar m√©todo `PromptAnalyzer.compact_prompt()`
3. Actualizar `intelligent_builder.py` para usar pipeline unificado
4. Tests de integraci√≥n

**Archivos a modificar:**
- `services/prompt_analyzer.py` (l√≠neas 612-804)
- `services/intelligent_builder.py` (l√≠nea 813)

**C√≥digo espec√≠fico:**

```python
# prompt_analyzer.py
class PromptAnalyzer:
    def __init__(
        self,
        # ... otros params
        prompt_compactor: Optional[PromptCompactor] = None
    ):
        self.prompt_compactor = prompt_compactor or PromptCompactor()

    def optimize_for_model(
        self,
        prompt: str,
        negative_prompt: str,
        base_model_architecture: str,
        quality: str = "balanced",
        enable_compaction: bool = True,  # NUEVO
    ) -> tuple[str, str]:
        """
        Optimiza prompts para arquitectura espec√≠fica.

        Si enable_compaction=True, garantiza ‚â§77 tokens.
        """
        # ... c√≥digo de optimizaci√≥n existente ...

        if enable_compaction:
            # Usar PromptCompactor dedicado
            result = self.prompt_compactor.compact(
                optimized_positive,
                preserve_nsfw=True
            )
            optimized_positive = result.compacted_prompt

            # Registrar warnings si hubo remoci√≥n de contenido
            if result.warnings:
                for warning in result.warnings:
                    logger.warning(f"Prompt compaction: {warning}")

        return optimized_positive, optimized_negative
```

**Resultado esperado:**
- ‚úÖ Un solo punto de compactaci√≥n
- ‚úÖ Comportamiento consistente
- ‚úÖ Logs de warnings cuando se remueve contenido

#### Tarea 1.2: Exportar content_tags (15 minutos)

**Objetivo:** Hacer m√≥dulo descubrible

**Acci√≥n:**
```python
# models/__init__.py - A√±adir al final:
from ml_lib.diffusion.models.content_tags import (
    NSFWCategory,
    PromptTokenPriority,
    TokenClassification,
    PromptCompactionResult,
    NSFWAnalysis,
    classify_token,
    analyze_nsfw_content,
)

# A√±adir a __all__
__all__ = [
    # ... existentes ...
    "NSFWCategory",
    "PromptTokenPriority",
    "TokenClassification",
    "PromptCompactionResult",
    "NSFWAnalysis",
    "classify_token",
    "analyze_nsfw_content",
]
```

#### Tarea 1.3: Fix inline imports (30 minutos)

**Objetivo:** Mover imports de stdlib a top

**Archivos:**
- `storage/user_preferences_db.py` (l√≠neas 294-295)
- Otros 4 casos detectados

**Ejemplo:**
```python
# ‚ùå ANTES
def record_generation(self, ...):
    import hashlib
    import json
    prompt_hash = hashlib.md5(...)

# ‚úÖ DESPU√âS
# Top del archivo
import hashlib
import json

def record_generation(self, ...):
    prompt_hash = hashlib.md5(...)
```

#### Tarea 1.4: Sistema de feedback al usuario (1.5 horas)

**Objetivo:** Usuario informado de modificaciones a su prompt

**Nueva clase:**

```python
# models/value_objects/processed_prompt.py
@dataclass
class ProcessedPrompt:
    """Resultado de procesamiento de prompt."""

    original: str
    final: str
    original_token_count: int
    final_token_count: int
    was_modified: bool
    modifications: list[str] = field(default_factory=list)
    removed_tokens: list[TokenClassification] = field(default_factory=list)
    warnings: list[str] = field(default_factory=list)

    @property
    def has_critical_loss(self) -> bool:
        """Verifica si se perdi√≥ contenido cr√≠tico."""
        return any(
            t.priority == PromptTokenPriority.CRITICAL
            for t in self.removed_tokens
        )

    def get_user_message(self) -> str:
        """Genera mensaje para mostrar al usuario."""
        if not self.was_modified:
            return "‚úì Prompt procesado sin cambios"

        parts = []
        parts.append(f"‚ö† Prompt modificado:")
        parts.append(f"  - Tokens: {self.original_token_count} ‚Üí {self.final_token_count}")

        if self.removed_tokens:
            removed_text = ", ".join(t.token for t in self.removed_tokens[:5])
            parts.append(f"  - Removido: {removed_text}")
            if len(self.removed_tokens) > 5:
                parts.append(f"    ... y {len(self.removed_tokens) - 5} m√°s")

        if self.has_critical_loss:
            parts.append("  ‚ö† ADVERTENCIA: Contenido cr√≠tico fue removido!")

        return "\n".join(parts)
```

**Uso en facade:**

```python
# facade.py
def generate_from_prompt(self, prompt: str, ...) -> Image.Image:
    # ... c√≥digo existente ...

    # Procesar prompt con feedback
    processed = self._pipeline.process_prompt(prompt, ...)

    # Mostrar mensaje al usuario si hubo cambios
    if processed.was_modified:
        logger.warning(processed.get_user_message())

    # Generar con prompt procesado
    image = self._pipeline.generate(
        prompt=processed.final,
        ...
    )

    return image
```

---

### ‚ö†Ô∏è FASE 2: ALTO - Esta Semana (12-16 horas)

#### Tarea 2.1: Integrar UserPreferencesDB (6-8 horas)

**Objetivo:** Conectar sistema de preferencias al pipeline

**Paso 1: A√±adir a IntelligentPipelineBuilder**

```python
# intelligent_builder.py
class IntelligentPipelineBuilder:
    def __init__(
        self,
        # ... params existentes
        user_preferences_db: Optional[UserPreferencesDB] = None,
        user_id: Optional[str] = None,
    ):
        self.user_prefs_db = user_preferences_db
        self.user_id = user_id

    def _select_models(self, config: GenerationConfig) -> SelectedModels:
        # ... c√≥digo existente ...

        # NUEVO: Aplicar preferencias de usuario
        if self.user_prefs_db and self.user_id:
            selected = self._apply_user_preferences(
                selected=selected,
                user_id=self.user_id
            )

        return selected

    def _apply_user_preferences(
        self,
        selected: SelectedModels,
        user_id: str
    ) -> SelectedModels:
        """Aplica preferencias de usuario a modelos seleccionados."""
        prefs = self.user_prefs_db.get_or_create_preferences(user_id)

        # Filtrar modelos bloqueados
        if selected.base_model_path.name in prefs.blocked_models:
            logger.info(f"Base model blocked by user, selecting alternative...")
            # Buscar alternativa
            pass

        # Filtrar LoRAs bloqueados
        filtered_loras = []
        filtered_weights = []
        for lora_path, weight in zip(selected.lora_paths, selected.lora_weights):
            if lora_path.name not in prefs.blocked_loras:
                filtered_loras.append(lora_path)
                filtered_weights.append(weight)

        selected.lora_paths = filtered_loras
        selected.lora_weights = filtered_weights

        # Aplicar preferencias de par√°metros
        if not config.steps:  # Usuario no especific√≥
            selected.steps = prefs.default_steps

        if not config.cfg_scale:
            selected.cfg_scale = prefs.default_cfg

        return selected
```

**Paso 2: Registrar generaciones**

```python
# intelligent_builder.py - al final de generate()
def generate(self, prompt: str, ...) -> Image.Image | list[Image.Image]:
    # ... c√≥digo de generaci√≥n existente ...

    # NUEVO: Registrar generaci√≥n en historial
    if self.user_prefs_db and self.user_id:
        self.user_prefs_db.record_generation(
            user_id=self.user_id,
            prompt=prompt,
            base_model=selected.base_model_path.name,
            loras=[p.name for p in selected.lora_paths],
            quality=config.quality,
            steps=selected.steps,
            cfg=selected.cfg_scale,
            sampler=selected.sampler,
            width=config.width,
            height=config.height,
            rating=None  # Usuario puede dar rating despu√©s
        )

    return images
```

**Paso 3: API en facade**

```python
# facade.py
class ImageGenerator:
    def __init__(
        self,
        # ... params existentes
        user_id: Optional[str] = None,
    ):
        self.user_id = user_id

        # Crear DB de preferencias
        if user_id:
            db_path = self.cache_dir / "user_preferences.db"
            self.user_prefs_db = UserPreferencesDB(db_path)
        else:
            self.user_prefs_db = None

    def set_favorite_model(self, model_name: str, model_type: str) -> None:
        """Marca modelo como favorito."""
        if not self.user_prefs_db or not self.user_id:
            raise ValueError("User ID required for preferences")

        self.user_prefs_db.add_favorite_model(
            user_id=self.user_id,
            model_name=model_name,
            model_type=model_type
        )

    def block_model(self, model_name: str, model_type: str, reason: str = "") -> None:
        """Bloquea modelo."""
        if not self.user_prefs_db or not self.user_id:
            raise ValueError("User ID required for preferences")

        self.user_prefs_db.block_model(
            user_id=self.user_id,
            model_name=model_name,
            model_type=model_type,
            reason=reason
        )
```

#### Tarea 2.2: Refactorizar dicts a clases (4-6 horas)

**Prioridad:** Casos m√°s cr√≠ticos primero

**Caso 1: NSFW_KEYWORDS**

```python
# ‚ùå ANTES - content_tags.py:57
NSFW_KEYWORDS: dict[NSFWCategory, list[str]] = {...}

# ‚úÖ DESPU√âS
@dataclass
class KeywordList:
    """Lista de keywords para una categor√≠a."""
    keywords: list[str]

    def contains(self, text: str) -> bool:
        """Verifica si texto contiene alg√∫n keyword."""
        text_lower = text.lower()
        return any(kw in text_lower for kw in self.keywords)

    def find_matches(self, text: str) -> list[str]:
        """Encuentra todos los keywords presentes en texto."""
        text_lower = text.lower()
        return [kw for kw in self.keywords if kw in text_lower]


class NSFWKeywordRegistry:
    """Registro de keywords NSFW por categor√≠a."""

    def __init__(self):
        self._categories: dict[NSFWCategory, KeywordList] = {}
        self._initialize_default_keywords()

    def _initialize_default_keywords(self) -> None:
        """Inicializa keywords por defecto."""
        self.register_category(
            NSFWCategory.ORAL,
            KeywordList([
                "fellatio", "blowjob", "oral", "deepthroat",
                # ...
            ])
        )
        # ... m√°s categor√≠as

    def register_category(
        self,
        category: NSFWCategory,
        keywords: KeywordList
    ) -> None:
        """Registra keywords para una categor√≠a."""
        self._categories[category] = keywords

    def get_keywords(self, category: NSFWCategory) -> KeywordList:
        """Obtiene keywords para una categor√≠a."""
        return self._categories.get(category, KeywordList([]))

    def find_categories(self, text: str) -> list[NSFWCategory]:
        """Encuentra categor√≠as presentes en texto."""
        found = []
        for category, keywords in self._categories.items():
            if keywords.contains(text):
                found.append(category)
        return found
```

**Caso 2: detected_acts en NSFWAnalysis**

```python
# ‚ùå ANTES
@dataclass
class NSFWAnalysis:
    detected_acts: dict[NSFWCategory, list[str]] = field(default_factory=dict)

# ‚úÖ DESPU√âS
@dataclass
class DetectedAct:
    """Acto NSFW detectado."""
    category: NSFWCategory
    keywords_found: list[str]

@dataclass
class DetectedActs:
    """Colecci√≥n de actos detectados."""
    acts: list[DetectedAct] = field(default_factory=list)

    def add_act(self, category: NSFWCategory, keywords: list[str]) -> None:
        """A√±ade acto detectado."""
        self.acts.append(DetectedAct(category, keywords))

    def get_by_category(self, category: NSFWCategory) -> Optional[DetectedAct]:
        """Obtiene acto por categor√≠a."""
        for act in self.acts:
            if act.category == category:
                return act
        return None

    @property
    def categories(self) -> list[NSFWCategory]:
        """Lista de categor√≠as detectadas."""
        return [act.category for act in self.acts]

@dataclass
class NSFWAnalysis:
    is_nsfw: bool
    confidence: float
    detected_acts: DetectedActs = field(default_factory=DetectedActs)  # ‚úÖ
    recommended_lora_tags: list[str] = field(default_factory=list)
```

#### Tarea 2.3: Sistema extensible de categor√≠as (6-8 horas)

**Ver dise√±o completo en PARTE 2, secci√≥n 4.3**

Implementar:
1. `ContentCategoryRegistry`
2. `ContentCategoryDefinition`
3. `KeywordSet`
4. Carga desde YAML
5. Tests

---

### üìä FASE 3: MEDIO - Pr√≥ximas 2 Semanas (12-16 horas)

#### Tarea 3.1: Suite completa de tests (8-12 horas)

**Tests cr√≠ticos a crear:**

1. `test_prompt_processing_pipeline.py`
   - Verificar compactaci√≥n correcta
   - Verificar preservaci√≥n de contenido NSFW
   - Verificar notificaciones al usuario

2. `test_user_preferences_integration.py`
   - Filtrado de modelos bloqueados
   - Aplicaci√≥n de favoritos
   - Registro de historial

3. `test_lora_selection_accuracy.py`
   - Matching correcto de NSFW acts
   - Scoring apropiado
   - Exclusi√≥n de anime/cartoon

4. `test_content_category_registry.py`
   - Registro de nuevos dominios
   - Clasificaci√≥n correcta
   - Extensibilidad

#### Tarea 3.2: Performance optimizations (3-4 horas)

1. Tokenizer cache compartido
2. Ollama async stop
3. Pre-warming de modelos
4. Cach√© de embeddings

---

## CHECKLIST DE IMPLEMENTACI√ìN

### D√≠a 1 (HOY)
- [ ] **1.1** Integrar PromptCompactor ‚Üí `prompt_analyzer.py`
- [ ] **1.2** Exportar content_tags ‚Üí `models/__init__.py`
- [ ] **1.3** Fix inline imports ‚Üí 5 archivos
- [ ] **1.4** Sistema de feedback ‚Üí `ProcessedPrompt` class
- [ ] **TEST:** Ejecutar `test_prompt_compaction.py`
- [ ] **TEST:** Verificar que warnings aparecen en logs

### D√≠a 2-3 (Integraci√≥n UserPrefs)
- [ ] **2.1.1** A√±adir UserPreferencesDB a builder
- [ ] **2.1.2** M√©todo `_apply_user_preferences()`
- [ ] **2.1.3** Registro de generaciones
- [ ] **2.1.4** API en facade (favorite, block)
- [ ] **TEST:** Crear `test_user_preferences_integration.py`
- [ ] **TEST:** Verificar filtrado de bloqueados

### D√≠a 4-5 (Refactoring)
- [ ] **2.2.1** NSFW_KEYWORDS ‚Üí NSFWKeywordRegistry
- [ ] **2.2.2** detected_acts ‚Üí DetectedActs
- [ ] **2.2.3** Todas las tuples ‚Üí Value Objects
- [ ] **2.2.4** Todos los any ‚Üí tipos espec√≠ficos
- [ ] **TEST:** Re-ejecutar todos los tests

### Semana 2 (Extensibilidad + Tests)
- [ ] **2.3** ContentCategoryRegistry completo
- [ ] **2.3** Config YAML para categor√≠as
- [ ] **3.1** Suite completa de tests
- [ ] **3.2** Optimizaciones de performance
- [ ] **DOC:** Actualizar README con nuevas features

---

## M√âTRICAS DE √âXITO

### Antes de implementaci√≥n
- ‚ùå C√≥digo nuevo sin usar: 3 archivos (634 l√≠neas)
- ‚ùå Violaciones de normas: 148 casos
- ‚ùå Cobertura de tests: <20%
- ‚ùå Precisi√≥n de prompts: Sin garant√≠a
- ‚ùå Extensibilidad: Hardcoded NSFW

### Despu√©s de implementaci√≥n
- ‚úÖ C√≥digo nuevo integrado: 100%
- ‚úÖ Violaciones de normas: <10 casos justificados
- ‚úÖ Cobertura de tests: >60%
- ‚úÖ Precisi√≥n de prompts: Garantizada con feedback
- ‚úÖ Extensibilidad: Sistema pluggable para nuevos dominios

---

## CONCLUSIONES

El m√≥dulo `ml_lib/diffusion/` tiene una **arquitectura s√≥lida** pero sufre de **problemas de integraci√≥n** y **deuda t√©cnica acumulada**.

**Puntos cr√≠ticos:**
1. C√≥digo nuevo valioso que no se est√° usando
2. Precisi√≥n de prompts comprometida
3. No preparado para roadmap futuro (fantas√≠a, dise√±os, etc.)

**Recomendaci√≥n:** Implementar Plan de Acci√≥n priorizando **Fase 1** (cr√≠tico) de inmediato. Con 4-6 horas de trabajo enfocado, el sistema pasar√° de 80% a 95% funcional.

**ROI estimado:**
- **Inversi√≥n:** 30-40 horas en 2 semanas
- **Retorno:** Sistema production-ready, extensible, mantenible
- **Beneficio a largo plazo:** F√°cil a√±adir nuevos dominios de contenido

---

**SIGUIENTE PASO:** Comenzar con Tarea 1.1 - Integrar PromptCompactor

**FIN DEL DOCUMENTO DE AUDITOR√çA**
